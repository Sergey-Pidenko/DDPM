{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget 'https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/DDPM.py' -O 'DDPM.py';\n!wget 'https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/VAE.py' -O 'VAE.py';\n!wget 'https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/DataReader.py' -O 'DataReader.py';\n!wget 'https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/Noise.py' -O 'Noise.py';","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:34.816336Z","iopub.execute_input":"2025-03-10T14:05:34.816669Z","iopub.status.idle":"2025-03-10T14:05:36.007099Z","shell.execute_reply.started":"2025-03-10T14:05:34.816642Z","shell.execute_reply":"2025-03-10T14:05:36.006104Z"}},"outputs":[{"name":"stdout","text":"--2025-03-10 14:05:34--  https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/DDPM.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1933 (1.9K) [text/plain]\nSaving to: ‘DDPM.py’\n\nDDPM.py             100%[===================>]   1.89K  --.-KB/s    in 0s      \n\n2025-03-10 14:05:35 (29.6 MB/s) - ‘DDPM.py’ saved [1933/1933]\n\n--2025-03-10 14:05:35--  https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/VAE.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5080 (5.0K) [text/plain]\nSaving to: ‘VAE.py’\n\nVAE.py              100%[===================>]   4.96K  --.-KB/s    in 0s      \n\n2025-03-10 14:05:35 (39.0 MB/s) - ‘VAE.py’ saved [5080/5080]\n\n--2025-03-10 14:05:35--  https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/DataReader.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 950 [text/plain]\nSaving to: ‘DataReader.py’\n\nDataReader.py       100%[===================>]     950  --.-KB/s    in 0s      \n\n2025-03-10 14:05:35 (34.7 MB/s) - ‘DataReader.py’ saved [950/950]\n\n--2025-03-10 14:05:35--  https://raw.githubusercontent.com/Sergey-Pidenko/DDPM/refs/heads/main/Noise.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 849 [text/plain]\nSaving to: ‘Noise.py’\n\nNoise.py            100%[===================>]     849  --.-KB/s    in 0s      \n\n2025-03-10 14:05:35 (39.5 MB/s) - ‘Noise.py’ saved [849/849]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm\nimport kagglehub\nimport gc\n\nimport VAE, DDPM, DataReader, Noise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:36.008457Z","iopub.execute_input":"2025-03-10T14:05:36.008744Z","iopub.status.idle":"2025-03-10T14:05:46.405299Z","shell.execute_reply.started":"2025-03-10T14:05:36.008718Z","shell.execute_reply":"2025-03-10T14:05:46.404468Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Параметры\nhigh_res_dir = kagglehub.dataset_download(\"arnaud58/flickrfaceshq-dataset-ffhq\")\nbatch_size = 8\nnum_workers = 4\n\n# Количество шагов\nT = 1000\n# Настройка бета (variance schedule) от 1e-4 до 0.02 в течение T шагов\nbetas = torch.linspace(1e-4, 0.02, T)\n\n# Параметры модели DDPM\nepochs = 10\nlearning_rate = 0.0001\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Инициализация модели\nddpm = DDPM.UNet(in_channels=7, out_channels=3, num_layers=4).to(device)\n# Функции потерь\nreconstruction_loss_fn = nn.MSELoss()\n\n# Оптимизатор\noptimizer = optim.Adam(ddpm.parameters(), lr=learning_rate)\n\nbest_val_loss = float('inf')  # Инициализация лучшего значения валидационной потери\nbest_model_path = 'best_model_DDPM.pth'  # Путь для сохранения лучшей модели\n\n\n# Загружаем модель\nvae = VAE.VAEUNet(latent_dim=1024, bilinear=True)\n# Загружаем сохранённые веса в модель\nvae.load_state_dict(torch.load(\"/kaggle/input/best_model_vae/pytorch/default/1/best_model_VAE.pth\", map_location=device, weights_only=True))\nvae = vae.to(device)\n# Переводим модель в режим оценки\nvae.eval();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:46.407224Z","iopub.execute_input":"2025-03-10T14:05:46.407646Z","iopub.status.idle":"2025-03-10T14:05:53.121077Z","shell.execute_reply.started":"2025-03-10T14:05:46.407621Z","shell.execute_reply":"2025-03-10T14:05:53.120023Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset = DataReader.SuperResolutionDataset(dir=high_res_dir, size=10000)\n# Определяем размеры разбиений\ntrain_size = int(0.8 * len(dataset))\nval_size = int(0.1 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\n# Разбиваем набор данных\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n# Создаем DataLoader для каждой выборки\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n# # Проверка даталоадера\n# for low_res, high_res in train_loader:\n#     print(low_res.shape)\n#     break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:53.122430Z","iopub.execute_input":"2025-03-10T14:05:53.122756Z","iopub.status.idle":"2025-03-10T14:05:53.569409Z","shell.execute_reply.started":"2025-03-10T14:05:53.122725Z","shell.execute_reply":"2025-03-10T14:05:53.568439Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def time_condition(tensor, shape=(512, 512)):\n    batch_size = tensor.size(0)\n    # Генерируем все необходимые seed\n    seeds = tensor.unsqueeze(1).unsqueeze(2).expand(batch_size, *shape)\n    # Создаем тензор случайных чисел\n    generated_tensors = torch.empty((batch_size, *shape))\n    \n    for i in range(batch_size):\n        torch.manual_seed(tensor[i].item())\n        generated_tensors[i] = torch.rand(*shape)\n        \n    return generated_tensors.unsqueeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:53.570404Z","iopub.execute_input":"2025-03-10T14:05:53.570724Z","iopub.status.idle":"2025-03-10T14:05:53.575395Z","shell.execute_reply.started":"2025-03-10T14:05:53.570699Z","shell.execute_reply":"2025-03-10T14:05:53.574338Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train(model, cond_model, train_loader, optimizer, loss_fn, device):\n    model.train()\n    for low_res, high_res in tqdm(train_loader, desc=\"Training\"):\n        t = torch.randint(0, T, (batch_size,), dtype=torch.long)\n        noisy_images, noise = Noise.q_sample(high_res, t, betas)\n\n        low_res, high_res = low_res.to(device), high_res.to(device)\n        noisy_images, noise = noisy_images.to(device), noise.to(device)\n        t_cond = time_condition(tensor=t).to(device)\n        \n        cond, _, _ = cond_model(low_res)\n\n        inp = torch.concat([noisy_images, cond, t_cond], dim=1)\n        \n        optimizer.zero_grad()\n        # Прямой проход\n        outputs = model(inp)\n        # Вычисление потери\n        loss = loss_fn(outputs, noise)\n        # Назад и оптимизация\n        loss.backward()\n        optimizer.step()\n        torch.cuda.empty_cache()\n        gc.collect()\n\ndef validate(model, cond_model, val_loader, loss_fn, device):\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for low_res, high_res in tqdm(val_loader, desc=\"Validation\"):\n            t = torch.randint(0, T, (batch_size,), dtype=torch.long)\n            noisy_images, noise = Noise.q_sample(high_res, t, betas)\n\n            low_res, high_res = low_res.to(device), high_res.to(device)\n            noisy_images, noise = noisy_images.to(device), noise.to(device)\n            t_cond = time_condition(tensor=t).to(device)\n            \n            cond, _, _ = cond_model(low_res)\n\n            inp = torch.concat([noisy_images, cond, t_cond], dim=1)\n            \n            # Прямой проход\n            outputs = model(inp)\n            # Вычисление потери\n            val_loss += loss_fn(outputs, noise).item()\n            torch.cuda.empty_cache()\n            gc.collect()\n\n    return val_loss / len(val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:53.576179Z","iopub.execute_input":"2025-03-10T14:05:53.576443Z","iopub.status.idle":"2025-03-10T14:05:53.592612Z","shell.execute_reply.started":"2025-03-10T14:05:53.576422Z","shell.execute_reply":"2025-03-10T14:05:53.591981Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for epoch in range(1, epochs + 1):\n    train(ddpm, vae, train_loader, optimizer, reconstruction_loss_fn, device)\n    train_loss = validate(ddpm, vae, train_loader, reconstruction_loss_fn, device)\n    val_loss = validate(ddpm, vae, val_loader, reconstruction_loss_fn, device)\n    print(f'Epoch [{epoch}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n\n    # Сохранение модели, если валидационная потеря улучшилась\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(ddpm.state_dict(), best_model_path)\n        print(f'Model saved at epoch {epoch} with validation loss: {val_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:05:53.593301Z","iopub.execute_input":"2025-03-10T14:05:53.593547Z","iopub.status.idle":"2025-03-10T16:45:45.076837Z","shell.execute_reply.started":"2025-03-10T14:05:53.593528Z","shell.execute_reply":"2025-03-10T16:45:45.075462Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 1000/1000 [50:10<00:00,  3.01s/it]\nValidation: 100%|██████████| 1000/1000 [19:54<00:00,  1.19s/it]\nValidation: 100%|██████████| 125/125 [02:28<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Train Loss: 0.0485, Validation Loss: 0.0483\nModel saved at epoch 1 with validation loss: 0.0483\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1000/1000 [49:52<00:00,  2.99s/it]\nValidation: 100%|██████████| 1000/1000 [19:49<00:00,  1.19s/it]\nValidation: 100%|██████████| 125/125 [02:29<00:00,  1.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Train Loss: 0.0377, Validation Loss: 0.0351\nModel saved at epoch 2 with validation loss: 0.0351\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|███       | 302/1000 [15:05<34:52,  3.00s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-981787378af1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d12e4cb3e7f0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, cond_model, train_loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Назад и оптимизация\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7}]}